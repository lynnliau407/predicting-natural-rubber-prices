{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ada6a3",
   "metadata": {},
   "source": [
    "# Section 0: Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and visualisation\n",
    "import pandas as pd                                                           # to deal with pandas dataframe\n",
    "import numpy as np                                                            # to deal with numbers\n",
    "import matplotlib.pyplot as plt                                               # to plot graphs\n",
    "\n",
    "# Statistical analysis\n",
    "from statsmodels.graphics import tsaplots                                     # to plot graphs\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf                 # to plot ACF and PACF graphs\n",
    "from statsmodels.tsa.stattools import adfuller                                # to perform ADF test\n",
    "import statsmodels.api as sm                                                  # for various statistical models\n",
    "import pmdarima as pm                                                         # for auto ARIMA model\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch             # diagnostic tests\n",
    "from arch import arch_model                                                   # for GARCH model\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing                  # for Holt's method model\n",
    "\n",
    "# Machine learning\n",
    "import tensorflow as tf                                                       # for deep learning\n",
    "from scipy.stats import randint, uniform                                      # for distribution used in RandomizedSearchCY\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score # to assess models' performance\n",
    "from sklearn.preprocessing import StandardScaler                              # for data scaling\n",
    "from keras.models import Sequential                                           # to build neural network models\n",
    "from keras.layers import LSTM, Dense, Dropout                                 # for LSTM networks\n",
    "from tensorflow.keras.optimizers import Adam                                  # for model optimization\n",
    "from scikeras.wrappers import KerasRegressor                                  # to integrate Keras with scikit-learn\n",
    "from sklearn.model_selection import RandomizedSearchCV                        # for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(15) # ensure reproducibility of LSTM results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422a567",
   "metadata": {},
   "source": [
    "# Section 1: Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ab58b",
   "metadata": {},
   "source": [
    "This section shows importing necessary packages, and data importation and cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32c72f",
   "metadata": {},
   "source": [
    "## Section 1.1: Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87763f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('C:\\Desktop\\smr20_2000-2024.csv')            # read SMR20 dataset \n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'])                  # convert Date column to datetime\n",
    "dataset.head()                                                     # show the first 5 rows of the data for review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf723123",
   "metadata": {},
   "source": [
    "## Section 1.2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0f2e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.info()                                                  # print information summary of the dataset \n",
    "null = dataset.isnull().sum()                                   # find the total no. of missing values in each column\n",
    "df_null = pd.DataFrame(data = null, columns = ['No. of Null'])  # create a dataframe to show the number of null\n",
    "print('\\n\\n', df_null)                                          # number of null in each column is shown\n",
    "print(f'\\n\\nThe total no. of null is  {sum(null)}')             # the total number of null is shown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6c469",
   "metadata": {},
   "source": [
    "# Section 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c0af6",
   "metadata": {},
   "source": [
    "## Section 2.1: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5dd79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the summary statistics of the date column\n",
    "dataset.Date.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8bdda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the summary statistics of dataset (by default numerical columns)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a87412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the minimum, maximum, average and standard deviation of each numerical column in each year\n",
    "for col in dataset.select_dtypes(exclude=['datetime64[ns]']).columns:\n",
    " desc_stat = dataset.groupby(dataset.Date.dt.year)[[col]].agg(['min','max','mean','std'])\n",
    " print(f'\\nDescriptive Statistics of:{desc_stat}')\n",
    " print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5671d3da",
   "metadata": {},
   "source": [
    "## Section 2.2: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a6218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the price over certain number of periods\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(dataset['Date'],dataset['Price'],label='Price')\n",
    "plt.legend(loc=0)\n",
    "plt.title('SMR20 Historical Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b216cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual price and its rolling mean over certain number of previous periods\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(dataset['Date'],dataset['Price'],label='Price')\n",
    "plt.plot(dataset['Date'],dataset['Price'].rolling(30).mean(),label='Rolling Mean (n=30)')\n",
    "plt.legend(loc=0)\n",
    "plt.title('SMR20 Historical Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a64bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1,2,figsize=(20, 8))\n",
    "# Autocorrelation plot\n",
    "fig=tsaplots.plot_acf(dataset['Price'], lags=72, alpha=0.05, ax=ax[0])\n",
    "# Partial autocorrelation plot\n",
    "fig=tsaplots.plot_pacf(dataset['Price'], lags=72,  alpha=0.05, ax=ax[1])\n",
    "for i in ax.flat:\n",
    "   i.set(xlabel='Lag at k', ylabel='Correlation coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36f667",
   "metadata": {},
   "source": [
    "# Section 3: Data Splitting and Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e221fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Date column as index\n",
    "dataset.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fa21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the data is sorted by Date\n",
    "dataset.sort_index(inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51554d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the proportion of data to use for training\n",
    "train_size = 0.9  # 90% of the data for training\n",
    "\n",
    "# Calculate the index at which to split the data\n",
    "split_index = int(len(dataset) * train_size)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train, test = dataset[:split_index], dataset[split_index:]\n",
    "\n",
    "# check the shape of train and test\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726419cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_train = train.copy()\n",
    "stat_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661065b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_train = train.copy()\n",
    "ml_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66842763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both the training and testing data\n",
    "train_data = scaler.fit_transform(ml_train)\n",
    "test_data = scaler.transform(ml_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e7c0c7",
   "metadata": {},
   "source": [
    "# Section 4: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63786701",
   "metadata": {},
   "source": [
    "## Section 4.1: ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c9eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(stat_train.dropna())\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ef176",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n",
    "\n",
    "# Original Series\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 8))\n",
    "axes[0, 0].plot(stat_train); axes[0, 0].set_title('Original Series')\n",
    "plot_acf(stat_train, ax=axes[0, 1])\n",
    "\n",
    "# 1st Differencing\n",
    "axes[1, 0].plot(stat_train.diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "plot_acf(stat_train.diff().dropna(), ax=axes[1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(stat_train.diff().dropna())\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(stat_train.diff().dropna(),lags=40,ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(stat_train.diff().dropna(),lags=40,ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac4798",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(stat_train, order=(1,1,0)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e16fd8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pmd_model = pm.auto_arima(stat_train, start_p=1, start_q=1,\n",
    "                      test='adf',       # use adftest to find optimal 'd'\n",
    "                      max_p=3, max_q=3, # maximum p and q\n",
    "                      m=1,              # frequency of series\n",
    "                      d=None,           # let model determine 'd'\n",
    "                      seasonal=False,   # No Seasonality\n",
    "                      start_P=0, \n",
    "                      D=0, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=True)\n",
    "\n",
    "print(pmd_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmd_model.plot_diagnostics(figsize = (15, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d11043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ACF for the residuals\n",
    "residuals = pd.DataFrame(model.resid)\n",
    "acf = sm.tsa.acf(residuals)\n",
    "\n",
    "# Plot ACF\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_acf(residuals, lags=20, ax=plt.gca())  # Adjust 'lags' as needed\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.title('Autocorrelation Function (ACF) of Residuals')\n",
    "\n",
    "# Plot PACF\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_pacf(residuals, lags=20, ax=plt.gca())\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Partial Autocorrelation')\n",
    "plt.title('Partial Autocorrelation Function (PACF) of Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise_arima = acorr_ljungbox(residuals, lags = [10], return_df=True)\n",
    "white_noise_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_pvalue = het_arch(residuals, ddof = 4)[1]\n",
    "print('LM-test-Pvalue:', '{:.5f}'.format(LM_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a8e10e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mdl_garch = arch_model(residuals, vol = 'GARCH', p = 1, q = 1)\n",
    "res_fit = mdl_garch.fit()\n",
    "print(res_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "garch_fit = res_fit\n",
    "\n",
    "garch_std_resid = pd.Series(garch_fit.resid / garch_fit.conditional_volatility)\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Residual\n",
    "garch_std_resid.plot(ax=fig.add_subplot(3, 1, 1), title='GARCH Standardized-Residual', legend=False)\n",
    "\n",
    "# ACF/PACF\n",
    "tsaplots.plot_acf(garch_std_resid, zero=False, lags=40, ax=fig.add_subplot(3, 2, 3))\n",
    "tsaplots.plot_pacf(garch_std_resid, zero=False, lags=40, ax=fig.add_subplot(3, 2, 4))\n",
    "\n",
    "# QQ-Plot & Norm-Dist\n",
    "sm.qqplot(garch_std_resid, line='s', ax=fig.add_subplot(3, 2, 5))\n",
    "plt.title(\"QQ Plot\")\n",
    "fig.add_subplot(3, 2, 6).hist(garch_std_resid, bins=40)\n",
    "plt.title(\"Histogram\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a82741",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise_garch = acorr_ljungbox(garch_std_resid, lags = [10], return_df=True)\n",
    "white_noise_garch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec64f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_pvalue = het_arch(garch_std_resid, ddof = 4)[1]\n",
    "print('LM-test-Pvalue:', '{:.5f}'.format(LM_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_train = model.predict(start = stat_train.index[1], end = stat_train.index[-1]) #When d=1 the first residual is nonsense\n",
    "forecast_test = model.predict(start = len(stat_train), end = len(dataset)-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GARCH to predict the residual\n",
    "garch_forecast = garch_fit.forecast(horizon=1)\n",
    "predicted_et = garch_forecast.mean['h.1'].iloc[-1]\n",
    "# Combine both models' output: yt = mu + et\n",
    "train_prediction = forecast_train + predicted_et\n",
    "test_prediction = forecast_test + predicted_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f94123",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_train.loc[:, 'ARIMA-GARCH Forecast'] = train_prediction\n",
    "stat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_test.loc[:, 'ARIMA-GARCH Forecast'] = test_prediction\n",
    "stat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459dc396",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "\n",
    "plt.plot(dataset.index[:len(stat_train)], dataset['Price'][:len(stat_train)], color='blue', label='Actual Train Price')\n",
    "plt.plot(stat_train.index, stat_train['ARIMA-GARCH Forecast'], color='red', label='Predicted Train Price')\n",
    "\n",
    "plt.title('Training Data and Predicted Values of ARIMA-GARCH Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test index after making predictions for the test data\n",
    "test_index = dataset.index[-len(test_prediction):]\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_index, stat_test['Price'], color='blue', label='Actual Test Price')\n",
    "plt.plot(test_index, stat_test['ARIMA-GARCH Forecast'], color='red', label='Predicted Test Price')\n",
    "plt.title('Test Data and Predicted Values of ARIMA-GARCH Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "\n",
    "plt.plot(dataset['Price'], color='blue', label='Actual Price')\n",
    "plt.plot(stat_test['ARIMA-GARCH Forecast'], color='red', label='Predicted Test Price')\n",
    "plt.title('Overall Data with Predicted Values for Test Data of ARIMA-GARCH Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fa3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(stat_train['Price'].iloc[1:], train_prediction))\n",
    "train_mae = mean_absolute_error(stat_train['Price'].iloc[1:], train_prediction)\n",
    "train_mape = np.mean(np.abs((stat_train['Price'].iloc[1:] - train_prediction) / stat_train['Price'])) * 100\n",
    "train_r2 = r2_score(stat_train['Price'].iloc[1:], train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = np.sqrt(mean_squared_error(stat_test['Price'], test_prediction))\n",
    "test_mae = mean_absolute_error(stat_test['Price'], test_prediction)\n",
    "test_mape = np.mean(np.abs((stat_test['Price'] - test_prediction) / stat_test['Price'])) * 100\n",
    "test_r2 = r2_score(stat_test['Price'], test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ada658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize evaluation metrics into a DataFrame\n",
    "metrics_data = {\n",
    "    'Metric': ['RMSE', 'MAE', 'MAPE', 'R2 Score'],\n",
    "    'Train': [train_rmse, train_mae, train_mape, train_r2],\n",
    "    'Test': [test_rmse, test_mae, test_mape, test_r2]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f92aea",
   "metadata": {},
   "source": [
    "## Section 4.2: Double Exponential Smoothing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f20733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Double Exponential Smoothing (Holt's method)\n",
    "DES_model = ExponentialSmoothing(stat_train['Price'], trend='add')\n",
    "result = DES_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast future prices\n",
    "forecast_train = result.predict(start=stat_train.index[0], end=stat_train.index[-1])  # Forecasting 12 months ahead\n",
    "forecast_test = result.forecast(steps=len(stat_test))  # Forecasting 12 months ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b5d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "\n",
    "plt.plot(dataset.index[:len(stat_train)], dataset['Price'][:len(stat_train)], color='blue', label='Actual Train Price')\n",
    "plt.plot(stat_train.index, forecast_train, color='red', label='Predicted Train Price')\n",
    "\n",
    "plt.title('Training Data and Predicted Values of DES Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test index after making predictions for the test data\n",
    "test_index = dataset.index[-len(forecast_test):]\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_index, stat_test['Price'], color='blue', label='Actual Test Price')\n",
    "plt.plot(test_index, forecast_test, color='red', label='Predicted Test Price')\n",
    "plt.title('Test Data and Predicted Values of DES Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef57d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecast\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(dataset, color='blue', label='Actual Price')\n",
    "plt.plot(forecast_test, color='red', label='Predicted Test Price')\n",
    "plt.title('Overall Data with Predicted Values for Test Data of DES Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(stat_train['Price'], forecast_train))\n",
    "train_mae = mean_absolute_error(stat_train['Price'], forecast_train)\n",
    "train_mape = np.mean(np.abs((stat_train['Price'] - forecast_train) / stat_train['Price'])) * 100\n",
    "train_r2 = r2_score(stat_train['Price'], forecast_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ead03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = np.sqrt(mean_squared_error(stat_test['Price'], forecast_test))\n",
    "test_mae = mean_absolute_error(stat_test['Price'], forecast_test)\n",
    "test_mape = np.mean(np.abs((stat_test['Price'] - forecast_test) / stat_test['Price'])) * 100\n",
    "test_r2 = r2_score(stat_test['Price'], forecast_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize evaluation metrics into a DataFrame\n",
    "metrics_data = {\n",
    "    'Metric': ['RMSE', 'MAE', 'MAPE', 'R2 Score'],\n",
    "    'Train': [train_rmse, train_mae, train_mape, train_r2],\n",
    "    'Test': [test_rmse, test_mae, test_mape, test_r2]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fcb3cb",
   "metadata": {},
   "source": [
    "## Section 4.3: LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences of data\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length), 0])\n",
    "        y.append(data[i + seq_length, 0])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aacc061",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sequences for training and testing\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create and compile the LSTM model\n",
    "def create_model(units=50, learning_rate=0.001, dropout_rate=0.2, batch_size=32,epochs=100):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(seq_length, 1)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=units))\n",
    "    model.add(Dense(units=1))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter distribution for randomized search\n",
    "param_dist = {\n",
    "    'model__units': randint(50, 150),               # Randomly select numbers of LSTM units\n",
    "    'model__learning_rate': uniform(0.0001, 0.01),  # Randomly select learning rates in range [0.0001, 0.01]\n",
    "    'model__epochs': [50, 100, 150],                # Select specific numbers of epochs\n",
    "    'model__dropout_rate': [0.1, 0.2, 0.3],         # Select specific dropout rates\n",
    "    'model__batch_size': [16, 32, 64]               # Select specific batch sizes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM model\n",
    "lstm_model = KerasRegressor(model=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(estimator=lstm_model, param_distributions=param_dist, n_iter=10, scoring='neg_mean_squared_error', cv=3)\n",
    "random_search_result = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaac302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and score\n",
    "print(\"Best Parameters:\", random_search_result.best_params_)\n",
    "print(\"Best Score:\", -random_search_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59967efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the best paramater\n",
    "best_units = random_search_result.best_params_['model__units']\n",
    "best_learning_rate = random_search_result.best_params_['model__learning_rate']\n",
    "best_epochs = random_search_result.best_params_['model__epochs']\n",
    "best_dropout_rate = random_search_result.best_params_['model__dropout_rate']\n",
    "best_batch_size = random_search_result.best_params_['model__batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best parameters to create and train the final model\n",
    "final_model = create_model(units=best_units, learning_rate=best_learning_rate, \n",
    "                           dropout_rate=best_dropout_rate, batch_size=best_batch_size)\n",
    "history = final_model.fit(X_train, y_train, epochs=best_epochs, batch_size=best_batch_size, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ded70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003584c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "train_predictions = final_model.predict(X_train)\n",
    "test_predictions = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the predictions\n",
    "train_predictions = scaler.inverse_transform(train_predictions)\n",
    "y_train = scaler.inverse_transform([y_train])\n",
    "test_predictions = scaler.inverse_transform(test_predictions)\n",
    "y_test = scaler.inverse_transform([y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b462496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Visualize the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plotting training data\n",
    "plt.plot(dataset.index[seq_length:seq_length+len(train_predictions)], y_train[0], color='blue', label='Actual Train Price')\n",
    "plt.plot(dataset.index[seq_length:seq_length+len(train_predictions)], train_predictions[:, 0], color='red', label='Predicted Train Price')\n",
    "\n",
    "plt.title('Training Data and Predicted Values of LSTM Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d10d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test index after making predictions for the test data\n",
    "test_index = dataset.index[-len(test_predictions):]\n",
    "\n",
    "# Third Graph: Test Data with Predicted Values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_index, y_test[0], color='blue', label='Actual Test Price')\n",
    "plt.plot(test_index, test_predictions[:, 0], color='red', label='Predicted Test Price')\n",
    "plt.title('Test Data and Predicted Values of LSTM Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8978e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Graph: Overall Data with Predicted Values for Test Data\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(dataset.index, dataset['Price'], color='blue', label='Actual Price')\n",
    "plt.plot(test_index, test_predictions[:, 0], color='red', label='Predicted Test Price')\n",
    "plt.title('Overall Data with Predicted Values for Test Data of LSTM Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train[0], train_predictions[:, 0]))\n",
    "train_mae = mean_absolute_error(y_train[0], train_predictions[:, 0])\n",
    "train_mape = np.mean(np.abs((y_train[0] - train_predictions[:, 0]) / y_train[0])) * 100\n",
    "train_r2 = r2_score(y_train[0], train_predictions[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = np.sqrt(mean_squared_error(y_test[0], test_predictions[:, 0]))\n",
    "test_mae = mean_absolute_error(y_test[0], test_predictions[:, 0])\n",
    "test_mape = np.mean(np.abs((y_test[0] - test_predictions[:, 0]) / y_test[0])) * 100\n",
    "test_r2 = r2_score(y_test[0], test_predictions[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize evaluation metrics into a DataFrame\n",
    "metrics_data = {\n",
    "    'Metric': ['RMSE', 'MAE', 'MAPE', 'R2 Score'],\n",
    "    'Train': [train_rmse, train_mae, train_mape, train_r2],\n",
    "    'Test': [test_rmse, test_mae, test_mape, test_r2]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
